{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQGs3QsZjadcCujbQ9oqU1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fberlatto/datasciencecoursera/blob/master/C%C3%B3pia_de_Tom_termos_capitulo_Covid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcvDFKPal32_"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Classificador de Tom por Matéria (ID) com agregação por referente (alvo).\n",
        "Unidade de decisão: matéria (id_materia), dentro de cada veículo.\n",
        "Entrada mínima: DataFrame com colunas ['veiculo','id_materia','trecho'].\n",
        "\n",
        "Saídas:\n",
        "- df_materias: um resumo por matéria com tom por alvo e tom geral (60%) + flag de sensibilidade (55%).\n",
        "- df_veiculos: agregados por veículo (% de documentos por tom geral).\n",
        "- df_tom_referente: opcional, Tom × Referente (% de documentos críticos/favoráveis/neutros por alvo).\n",
        "\n",
        "Regras principais (como definido no método do capítulo):\n",
        "1) No nível do trecho: contar predicados avaliativos POS/NEG por ALVO (Presidência; Ministro/MRE; Instituições),\n",
        "   com inversão por negação (\"não\", \"nunca\", \"jamais\") até 2 tokens antes do predicado.\n",
        "2) No nível da matéria: para cada ALVO, rotular CRÍTICO/FAVORÁVEL/NEUTRO por maioria qualificada (≥60%).\n",
        "3) Tom GERAL da matéria = rótulo do ALVO predominante (maior nº de predicados avaliativos).\n",
        "   Empate ou ausência de maioria → NEUTRO. Sensibilidade: testar 55%.\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Vocabulários e dicionários\n",
        "# ----------------------------\n",
        "\n",
        "# Alvos: termos que, se presentes no trecho, ativam contagem para esse referente.\n",
        "ALVOS = {\n",
        "    \"presidencia\": [\n",
        "        r\"\\bpresidente\\b\", r\"\\bbolsonaro\\b\", r\"\\bplanalto\\b\", r\"\\bpresid[eê]ncia\\b\"\n",
        "    ],\n",
        "    \"ministro_mre\": [\n",
        "        r\"\\bministro\\b\", r\"\\bchanceler\\b\", r\"\\bernesto\\b\", r\"\\bara[uú]jo\\b\",\n",
        "        r\"\\bfran[çc]a\\b\", r\"\\bcarlos\\s+fran[çc]a\\b\", r\"\\bminist[eé]rio\\b\"\n",
        "    ],\n",
        "    \"instituicao\": [\n",
        "        r\"\\bitamaraty\\b\", r\"\\bminist[eé]rio das rela[cç][oõ]es exteriores\\b\",\n",
        "        r\"\\brela[cç][oõ]es\\b\", r\"\\bexteriores\\b\", r\"\\banvisa\\b\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Predicados avaliativos (lista compacta e transparente).\n",
        "PRED_FAVORAVEIS = [\n",
        "    r\"\\bacertou\\b\", r\"\\bdefendeu\\b\", r\"\\brefor[cç]ou\\b\", r\"\\bavançou\\b\", r\"\\bresolver?\\b\",\n",
        "    r\"\\beficaz\\b\", r\"\\bcooperou\\b\", r\"\\bestabilizou\\b\", r\"\\bnegociou\\b\", r\"\\bconseguiu\\b\",\n",
        "    r\"\\baumentou\\b\", r\"\\bviabilizou\\b\", r\"\\bgarantiu\\b\"\n",
        "]\n",
        "\n",
        "PRED_CRITICOS = [\n",
        "    r\"\\bfalhou\\b\", r\"\\bdescumpriu\\b\", r\"\\bomie?ss?[aã]o\\b\", r\"\\bpressionou\\b\", r\"\\batacou\\b\",\n",
        "    r\"\\birregularidade\\b\", r\"\\bnegou\\b\", r\"\\binefic[aá]cia?\\b\", r\"\\bmentiu\\b\", r\"\\bboicotou\\b\",\n",
        "    r\"\\bimpediu\\b\", r\"\\bretardou\\b\", r\"\\bdesinformou\\b\", r\"\\bculpa\\b\", r\"\\berro\\b\"\n",
        "]\n",
        "\n",
        "# Marcadores explícitos de responsabilização/validação (entram como +1 no saldo correspondente).\n",
        "RESP_NEG = [r\"\\bresponsabilidade\\b\", r\"\\binvestiga[cç][aã]o\\b\", r\"\\bapura[cç][aã]o\\b\", r\"\\brelat[óo]rio\\s+aponta\\b\"]\n",
        "RESP_POS = [r\"\\baprova[cç][aã]o\\b\", r\"\\bparecer\\b\", r\"\\bautoriz[aã]o\\b\", r\"\\bvalida[cç][aã]o\\b\"]\n",
        "\n",
        "# Negadores que invertem o predicado se ocorrerem até 2 tokens antes.\n",
        "NEGADORES = [r\"\\bn[aã]o\\b\", r\"\\bnunca\\b\", r\"\\bjamais\\b\"]\n",
        "\n",
        "# Compilações regex\n",
        "def compile_list(patterns: List[str]) -> List[re.Pattern]:\n",
        "    return [re.compile(pat, flags=re.IGNORECASE | re.UNICODE) for pat in patterns]\n",
        "\n",
        "ALVOS_RX = {k: compile_list(v) for k, v in ALVOS.items()}\n",
        "FAV_RX = compile_list(PRED_FAVORAVEIS)\n",
        "CRI_RX = compile_list(PRED_CRITICOS)\n",
        "RESP_NEG_RX = compile_list(RESP_NEG)\n",
        "RESP_POS_RX = compile_list(RESP_POS)\n",
        "NEG_RX = compile_list(NEGADORES)\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Utilitários de texto\n",
        "# ----------------------------\n",
        "\n",
        "TOKEN_RX = re.compile(r\"[A-Za-zÀ-ÖØ-öø-ÿ0-9\\-]+\", flags=re.UNICODE)\n",
        "\n",
        "def tokenize(text: str) -> List[str]:\n",
        "    return TOKEN_RX.findall(text.lower())\n",
        "\n",
        "def contains_any(text: str, patterns: List[re.Pattern]) -> bool:\n",
        "    return any(p.search(text) for p in patterns)\n",
        "\n",
        "def find_spans(text: str, patterns: List[re.Pattern]) -> List[Tuple[int, int]]:\n",
        "    spans = []\n",
        "    for p in patterns:\n",
        "        for m in p.finditer(text):\n",
        "            spans.append((m.start(), m.end()))\n",
        "    return spans\n",
        "\n",
        "def has_negation_before(text: str, span_start: int, window_tokens: int = 2) -> bool:\n",
        "    \"\"\"\n",
        "    Procura negadores até 'window_tokens' tokens antes do predicado.\n",
        "    \"\"\"\n",
        "    # recorta um pedaço do texto antes do predicado\n",
        "    prefix = text[:span_start]\n",
        "    toks = tokenize(prefix)\n",
        "    # últimos 'window_tokens' tokens\n",
        "    toks = toks[-window_tokens:] if len(toks) >= window_tokens else toks\n",
        "    # verifica se algum é negador\n",
        "    for t in toks:\n",
        "        for neg in NEG_RX:\n",
        "            if neg.fullmatch(t):\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Contagem de predicados por alvo, no nível do trecho\n",
        "# ----------------------------\n",
        "\n",
        "def alvos_presentes(text: str) -> List[str]:\n",
        "    presentes = []\n",
        "    for alvo, pats in ALVOS_RX.items():\n",
        "        if contains_any(text, pats):\n",
        "            presentes.append(alvo)\n",
        "    return presentes\n",
        "\n",
        "def contagem_polaridade_por_alvo(text: str) -> Dict[str, Counter]:\n",
        "    \"\"\"\n",
        "    Para cada alvo presente no trecho, conta predicados favoráveis/críticos\n",
        "    (com inversão por negação). Também soma marcadores de responsabilização/validação.\n",
        "    Retorna: dict alvo -> Counter({'pos': x, 'neg': y, 'tot': x+y})\n",
        "    \"\"\"\n",
        "    out = {a: Counter(pos=0, neg=0, tot=0) for a in ALVOS.keys()}\n",
        "    alvos = alvos_presentes(text)\n",
        "    if not alvos:\n",
        "        return out\n",
        "\n",
        "    # 1) Predicados explícitos\n",
        "    for pats, label in ((FAV_RX, \"pos\"), (CRI_RX, \"neg\")):\n",
        "        for p in pats:\n",
        "            for m in p.finditer(text):\n",
        "                invert = has_negation_before(text, m.start(), window_tokens=2)\n",
        "                lab = \"neg\" if (label == \"pos\" and invert) else (\"pos\" if (label == \"neg\" and invert) else label)\n",
        "                for a in alvos:\n",
        "                    out[a][lab] += 1\n",
        "                    out[a][\"tot\"] += 1\n",
        "\n",
        "    # 2) Marcadores de responsabilidade/validação (pesam 1 no saldo)\n",
        "    if contains_any(text, RESP_NEG_RX):\n",
        "        for a in alvos:\n",
        "            out[a][\"neg\"] += 1\n",
        "            out[a][\"tot\"] += 1\n",
        "    if contains_any(text, RESP_POS_RX):\n",
        "        for a in alvos:\n",
        "            out[a][\"pos\"] += 1\n",
        "            out[a][\"tot\"] += 1\n",
        "\n",
        "    return out\n",
        "\n",
        "def rotulo_por_alvo(counter: Counter, limiar: float = 0.60) -> str:\n",
        "    pos, neg, tot = counter[\"pos\"], counter[\"neg\"], counter[\"tot\"]\n",
        "    if tot == 0:\n",
        "        return \"neutro\"\n",
        "    if neg / tot >= limiar:\n",
        "        return \"crítico\"\n",
        "    if pos / tot >= limiar:\n",
        "        return \"favorável\"\n",
        "    return \"neutro\"\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Consolidação por matéria (ID) e por veículo\n",
        "# ----------------------------\n",
        "\n",
        "def classificar_tom_por_materia(df: pd.DataFrame,\n",
        "                                col_veiculo=\"veiculo\",\n",
        "                                col_id=\"id_materia\",\n",
        "                                col_trecho=\"trecho\",\n",
        "                                limiar_principal=0.60,\n",
        "                                limiar_sensib=0.55) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Retorna:\n",
        "    - df_materias: tom por alvo e tom geral da matéria (+ flag limítrofe se 55% mudasse o rótulo).\n",
        "    - df_veiculos: % de documentos por tom geral (por veículo).\n",
        "    - df_tom_referente: % de documentos por tom × referente (opcional, útil para apêndice).\n",
        "    \"\"\"\n",
        "    registros_materia = []\n",
        "    # Para Tom × Referente\n",
        "    reg_referente = []\n",
        "\n",
        "    # Agrupa por veículo e matéria\n",
        "    for (veic, mid), grupo in df.groupby([col_veiculo, col_id]):\n",
        "        # acumula contagens POS/NEG por alvo somando todos os trechos da matéria\n",
        "        totals = {a: Counter(pos=0, neg=0, tot=0) for a in ALVOS.keys()}\n",
        "        for _, row in grupo.iterrows():\n",
        "            txt = str(row[col_trecho])\n",
        "            parc = contagem_polaridade_por_alvo(txt)\n",
        "            for a in ALVOS.keys():\n",
        "                totals[a][\"pos\"] += parc[a][\"pos\"]\n",
        "                totals[a][\"neg\"] += parc[a][\"neg\"]\n",
        "                totals[a][\"tot\"] += parc[a][\"tot\"]\n",
        "\n",
        "        # rótulos por alvo com limiar principal\n",
        "        rotulos_60 = {a: rotulo_por_alvo(totals[a], limiar_principal) for a in ALVOS.keys()}\n",
        "        # rótulos por alvo com limiar alternativo (sensibilidade)\n",
        "        rotulos_55 = {a: rotulo_por_alvo(totals[a], limiar_sensib) for a in ALVOS.keys()}\n",
        "\n",
        "        # alvo predominante = maior nº de predicados avaliativos\n",
        "        alvo_pred = max(ALVOS.keys(), key=lambda a: totals[a][\"tot\"])\n",
        "        # se nenhum alvo teve predicados, usar presidência por padrão para o geral (fica neutro)\n",
        "        if all(totals[a][\"tot\"] == 0 for a in ALVOS.keys()):\n",
        "            alvo_pred = \"presidencia\"\n",
        "\n",
        "        tom_geral_60 = rotulos_60[alvo_pred]\n",
        "        tom_geral_55 = rotulos_55[alvo_pred]\n",
        "        limítrofe = (tom_geral_60 != tom_geral_55)\n",
        "\n",
        "        registro = {\n",
        "            \"veiculo\": veic,\n",
        "            \"id_materia\": mid,\n",
        "            \"alvo_predominante\": alvo_pred,\n",
        "            \"tom_geral\": tom_geral_60,\n",
        "            \"tom_geral_sensib55\": tom_geral_55,\n",
        "            \"limítrofe_55\": limítrofe,\n",
        "        }\n",
        "        # coloca também os rótulos por alvo e as contagens\n",
        "        for a in ALVOS.keys():\n",
        "            registro[f\"{a}_rotulo\"] = rotulos_60[a]\n",
        "            registro[f\"{a}_pos\"] = totals[a][\"pos\"]\n",
        "            registro[f\"{a}_neg\"] = totals[a][\"neg\"]\n",
        "            registro[f\"{a}_tot\"] = totals[a][\"tot\"]\n",
        "            # para Tom × Referente\n",
        "            reg_referente.append({\n",
        "                \"veiculo\": veic,\n",
        "                \"id_materia\": mid,\n",
        "                \"referente\": a,\n",
        "                \"tom\": rotulos_60[a]\n",
        "            })\n",
        "\n",
        "        registros_materia.append(registro)\n",
        "\n",
        "    df_materias = pd.DataFrame(registros_materia)\n",
        "\n",
        "    # Agregado por veículo (% de documentos por tom geral)\n",
        "    def pct_docs(grp):\n",
        "        n = len(grp)\n",
        "        return (grp[\"tom_geral\"].value_counts(normalize=True) * 100).round(1).rename_axis(\"tom\").reset_index(name=\"%docs\")\n",
        "\n",
        "    df_veiculos = (df_materias.groupby(\"veiculo\", as_index=False)\n",
        "                   .apply(pct_docs)\n",
        "                   .reset_index(drop=True))\n",
        "\n",
        "    # Tom × Referente (% de documentos por veículo e referente)\n",
        "    def pct_docs_ref(grp):\n",
        "        n = grp[\"id_materia\"].nunique()\n",
        "        # um doc conta 1 vez por (referente, tom) — pegamos rotulo único por id\n",
        "        unique = grp.drop_duplicates(subset=[\"id_materia\",\"referente\"])[[\"referente\",\"tom\"]]\n",
        "        out = (unique.value_counts(normalize=True) * 100).round(1).rename(\"%docs\").reset_index()\n",
        "        return out\n",
        "\n",
        "    df_ref = pd.DataFrame(reg_referente)\n",
        "    df_tom_referente = (df_ref.groupby([\"veiculo\"], as_index=False)\n",
        "                        .apply(pct_docs_ref)\n",
        "                        .reset_index(drop=True))\n",
        "\n",
        "    return df_materias, df_veiculos, df_tom_referente\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Exemplo de uso\n",
        "# ----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Exemplo mínimo (substitua pelo seu DataFrame real):\n",
        "    dados = pd.DataFrame({\n",
        "        \"veiculo\": [\"Folha de S.Paulo\",\"Folha de S.Paulo\",\"Valor Economico\",\"Gazeta do Povo\"],\n",
        "        \"id_materia\": [\"Folha>27\",\"Folha>27\",\"Valor>203\",\"Gazeta>592\"],\n",
        "        \"trecho\": [\n",
        "            \"CPI da Covid aprova relatório e pede punição de Bolsonaro por crimes na pandemia.\",\n",
        "            \"O ministro das Relações Exteriores, Carlos França, participou da reunião com chanceleres.\",\n",
        "            \"O novo ministro Carlos França discutiu cooperação com a China; Anvisa aprova uso emergencial.\",\n",
        "            \"Bolsonaro conversou com o chanceler Carlos França e o ministro da Saúde sobre vacinas.\"\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    df_materias, df_veiculos, df_tom_ref = classificar_tom_por_materia(dados)\n",
        "\n",
        "    print(\"\\n=== Tom por matéria (resumo) ===\")\n",
        "    print(df_materias.head(10).to_string(index=False))\n",
        "\n",
        "    print(\"\\n=== % de documentos por tom (por veículo) ===\")\n",
        "    print(df_veiculos.to_string(index=False))\n",
        "\n",
        "    print(\"\\n=== Tom × Referente (%docs) — opcional ===\")\n",
        "    print(df_tom_ref.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "skF0sg2LmzSO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IS_6W3Aymz-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gLpjOa-9l6M0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}